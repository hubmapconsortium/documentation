{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017c233f",
   "metadata": {},
   "source": [
    "# Using SearchSDK and EntitySDK \n",
    "\n",
    "### Example 1: Querying Search API for Datasets with the Data Type \"CODEX\" and Then Retrieving All Info on Each Dataset Via the Entity API\n",
    "\n",
    "Begin by importing the **hubmap-sdk**. Then create an instance of both the search sdk and entity sdk. For this demo, we will set the service url to point at the DEV versions of the entity api and search api. By default, the service url is the PROD version of these web services. We will be only looking at publicly accessible endpoints and entitites, however if you had a Globus Groups Token with access to additional priviledges, you could add them as an argument with **token=**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832b230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hubmap_sdk\n",
    "\n",
    "search_instance = hubmap_sdk.SearchSdk(service_url='https://search-api.dev.hubmapconsortium.org/')\n",
    "entity_instance = hubmap_sdk.EntitySdk(service_url='https://entity-api.dev.hubmapconsortium.org/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f17b0f8",
   "metadata": {},
   "source": [
    "Next we need to prepare a search query. For this demonstration, we will be searching for datasets of the data type 'CODEX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eb89d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = {\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"data_types\": \"CODEX\"\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20c605a",
   "metadata": {},
   "source": [
    "Now that we have a query, we can use the search sdk. We pass the query as a dictionary object to the search() method of the search instance we created earlier. The output will be a dictionary, which we save as **results_dict**. \n",
    "\n",
    "The basic structure of the results dictionary is:\n",
    "\n",
    "```python\n",
    "{\n",
    "    '_shards': {\n",
    "        'failed':___,\n",
    "        'skipped':___ ,\n",
    "        'successful':___ ,\n",
    "        'total':___ \n",
    "    },\n",
    "    'hits': {\n",
    "        'hits': [___],\n",
    "        'max_score':___,\n",
    "        'total': {\n",
    "            'relation':___,\n",
    "            'value':___\n",
    "        }\n",
    "    },\n",
    "    'timed_out':___,\n",
    "    'took':___\n",
    "}\n",
    "```\n",
    "\n",
    "so we access the list of hits by using the top level key _'hits'_ and then the key one level down also called _'hits'_. We will save this as **list_of_hits**. Lastly we'll create an empty **list list_of_datasets** which we'll use in a moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fa1490",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = search_instance.search(search_query)\n",
    "list_of_hits = results_dict[\"hits\"][\"hits\"]\n",
    "list_of_datasets = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8674a7d",
   "metadata": {},
   "source": [
    "For each dataset returned to us from the search sdk, we will retrieve its data via the entity api. In a for-loop, we'll call the **get_entity()** method of the entity sdk and pass it the uuid for each hit.This is given by the attribute **'\\_id'**. We set that output to **dataset** and then add each dataset to **list_of_datasets**. Now we have a list of all the dataset objects that match our search query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0098e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hit in list_of_hits:\n",
    "    dataset = entity_instance.get_entity_by_id(hit[\"_id\"])\n",
    "    list_of_datasets.append(dataset)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc1d595",
   "metadata": {},
   "source": [
    "Lastly, lets display some info to demonstrate that it worked. We'll just loop through the datasets and display a few attributes of each. By default, 10 hits are returned; this can be configured in the search query. We can see that each one has the data type 'CODEX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21b6307",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in list_of_datasets:\n",
    "    print(f\"HuBMAP ID: {dataset.hubmap_id}\")\n",
    "    print(f\"Created By User Displayname: {dataset.created_by_user_displayname}\")\n",
    "    print(f\"Group Name: {dataset.group_name}\")\n",
    "    print(f\"Data Types: {dataset.data_types} \\n\\n\")\n",
    "    print(f\"bills\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
